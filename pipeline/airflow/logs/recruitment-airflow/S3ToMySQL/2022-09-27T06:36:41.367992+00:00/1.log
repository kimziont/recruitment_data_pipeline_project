[2022-09-27 06:38:55,864] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: recruitment-airflow.S3ToMySQL manual__2022-09-27T06:36:41.367992+00:00 [queued]>
[2022-09-27 06:38:55,887] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: recruitment-airflow.S3ToMySQL manual__2022-09-27T06:36:41.367992+00:00 [queued]>
[2022-09-27 06:38:55,889] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2022-09-27 06:38:55,889] {taskinstance.py:1242} INFO - Starting attempt 1 of 1
[2022-09-27 06:38:55,890] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-09-27 06:38:55,951] {taskinstance.py:1262} INFO - Executing <Task(BashOperator): S3ToMySQL> on 2022-09-27 06:36:41.367992+00:00
[2022-09-27 06:38:55,954] {standard_task_runner.py:52} INFO - Started process 456 to run task
[2022-09-27 06:38:55,956] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'recruitment-airflow', 'S3ToMySQL', 'manual__2022-09-27T06:36:41.367992+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/recruitment_pipeline.py', '--cfg-path', '/tmp/tmpq2gymcy1', '--error-file', '/tmp/tmpnznwv3zi']
[2022-09-27 06:38:55,957] {standard_task_runner.py:77} INFO - Job 13: Subtask S3ToMySQL
[2022-09-27 06:38:56,038] {logging_mixin.py:109} INFO - Running <TaskInstance: recruitment-airflow.S3ToMySQL manual__2022-09-27T06:36:41.367992+00:00 [running]> on host pipeline
[2022-09-27 06:38:56,087] {logging_mixin.py:109} WARNING - /usr/local/lib/python3.8/site-packages/airflow/models/xcom.py:323 SAWarning: TypeDecorator UtcDateTime(timezone=True) will not produce a cache key because the ``cache_ok`` attribute is not set to True.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Set this attribute to True if this type object's state is safe to use in a cache key, or False to disable this warning. (Background on this error at: https://sqlalche.me/e/14/cprf)
[2022-09-27 06:38:56,106] {logging_mixin.py:109} WARNING - /usr/local/lib/python3.8/site-packages/airflow/models/renderedtifields.py:126 SAWarning: TypeDecorator UtcDateTime(timezone=True) will not produce a cache key because the ``cache_ok`` attribute is not set to True.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Set this attribute to True if this type object's state is safe to use in a cache key, or False to disable this warning. (Background on this error at: https://sqlalche.me/e/14/cprf)
[2022-09-27 06:38:56,146] {logging_mixin.py:109} WARNING - /usr/local/lib/python3.8/site-packages/airflow/models/renderedtifields.py:162 SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly
[2022-09-27 06:38:56,150] {logging_mixin.py:109} WARNING - /usr/local/lib/python3.8/site-packages/airflow/models/renderedtifields.py:159 SAWarning: TypeDecorator UtcDateTime(timezone=True) will not produce a cache key because the ``cache_ok`` attribute is not set to True.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Set this attribute to True if this type object's state is safe to use in a cache key, or False to disable this warning. (Background on this error at: https://sqlalche.me/e/14/cprf)
[2022-09-27 06:38:56,163] {taskinstance.py:1427} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=recruitment-airflow
AIRFLOW_CTX_TASK_ID=S3ToMySQL
AIRFLOW_CTX_EXECUTION_DATE=2022-09-27T06:36:41.367992+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-09-27T06:36:41.367992+00:00
[2022-09-27 06:38:56,165] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-09-27 06:38:56,166] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'python /opt/pipeline/script/S3ToMySQL.py']
[2022-09-27 06:38:56,171] {subprocess.py:85} INFO - Output:
[2022-09-27 06:38:56,269] {subprocess.py:89} INFO - Traceback (most recent call last):
[2022-09-27 06:38:56,270] {subprocess.py:89} INFO -   File "/opt/pipeline/script/S3ToMySQL.py", line 4, in <module>
[2022-09-27 06:38:56,271] {subprocess.py:89} INFO -     import mysql.connector
[2022-09-27 06:38:56,273] {subprocess.py:89} INFO - ModuleNotFoundError: No module named 'mysql'
[2022-09-27 06:38:56,292] {subprocess.py:93} INFO - Command exited with return code 1
[2022-09-27 06:38:56,311] {taskinstance.py:1703} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1332, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/usr/local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1458, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/usr/local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1514, in _execute_task
    result = execute_callable(context=context)
  File "/usr/local/lib/python3.8/site-packages/airflow/operators/bash.py", line 187, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2022-09-27 06:38:56,318] {taskinstance.py:1270} INFO - Marking task as FAILED. dag_id=recruitment-airflow, task_id=S3ToMySQL, execution_date=20220927T063641, start_date=20220927T063855, end_date=20220927T063856
[2022-09-27 06:38:56,390] {standard_task_runner.py:88} ERROR - Failed to execute job 13 for task S3ToMySQL
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/usr/local/lib/python3.8/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 292, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/usr/local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/usr/local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 180, in _run_raw_task
    ti._run_raw_task(
  File "/usr/local/lib/python3.8/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1332, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/usr/local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1458, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/usr/local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1514, in _execute_task
    result = execute_callable(context=context)
  File "/usr/local/lib/python3.8/site-packages/airflow/operators/bash.py", line 187, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2022-09-27 06:38:56,414] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-09-27 06:38:56,446] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-09-27 06:38:56,448] {logging_mixin.py:109} WARNING - /usr/local/lib/python3.8/site-packages/airflow/models/dag.py:1069 SADeprecationWarning: Query.value() is deprecated and will be removed in a future release.  Please use Query.with_entities() in combination with Query.scalar() (deprecated since: 1.4)
[2022-09-27 06:38:56,449] {logging_mixin.py:109} WARNING - /usr/local/lib/python3.8/site-packages/airflow/models/dag.py:1069 SADeprecationWarning: Query.values() is deprecated and will be removed in a future release.  Please use Query.with_entities() (deprecated since: 1.4)
