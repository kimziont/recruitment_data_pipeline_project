version: '3.2'

services:

  pipeline:
    image: ziontkim0510/data-engineering-python:1.2
    hostname: pipeline
    ports:
      - "49999:8888"
    volumes:
      - ./pipeline/jupyter:/opt/pipeline/jupyter
      - ./pipeline/script:/opt/pipeline/script
      - ./pipeline/airflow:/opt/pipeline/airflow
    tty: true

  mongodb:
    image: mongo:latest
    hostname: mongodb
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: root
    volumes:
      - ./data/mongo/data:/data/db
    tty: true

  zookeeper:
    image: zookeeper:3.7
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
    volumes:
      - ./data/zookeeper/data:/data
      - ./data/zookeeper/datalog:/datalogco

  kafka:
    image: ziontkim0510/kafka:1.1
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      AUTO_CREATE_TOPICS_ENABLE: "true"
    tty: true
    volumes:
      - ./data/kafka/data:/tmp/kafka-logs
    depends_on:
      - zookeeper
  
  mysql:
    hostname: mysql
    image: ziontkim0510/mysql-server:1.2
    ports:
      - 3306:3306
    environment:
      MYSQL_USER: root
      MYSQL_ROOT_HOST: "%%"
      MYSQL_DATABASE: test
      MYSQL_ROOT_PASSWORD: passwd
    command: mysqld
      --server-id=1234
      --max-binlog-size=4096
      --binlog-format=ROW
      --log-bin=bin-log
      --sync-binlog=1
      --binlog-rows-query-log-events=ON
    volumes:
      - ./dataset:/var/lib/mysql-files

  mysqld-exporter:
    hostname: mysqld-exporter
    image: prom/mysqld-exporter
    ports:
      - 9104:9104
    environment:
      DATA_SOURCE_NAME: root:passwd@(mysql:3306)/

  prometheus:
    hostname: prometheus
    image: prom/prometheus
    ports:
      - 9090:9090
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml


  grafana:
    hostname: grafana
    image: grafana/grafana
    ports:
      - 3000:3000

  superset:
    hostname: superset
    image: ziontkim0510/superset:1.0
    ports:
    - 8088:8088
  
  elasticsearch:
    image: elasticsearch:7.16.2
    hostname: elasticsearch
    volumes:
      - type: bind
        source: ./elasticsearch/config/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      - type: volume
        source: elasticsearch
        target: /usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
      ELASTIC_PASSWORD: changeme
      ELASTIC_USERNAME: elastic
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node

  django-project:
    image: ziontkim0510/django:1.1
    hostname: django-project
    ports:
      - "8000:8000"
    volumes:
      - ./django:/opt/recruitment
    tty: true


volumes:
  elasticsearch: